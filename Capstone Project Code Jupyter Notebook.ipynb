{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Capstone Project Code - Jupyter Notebook:\n## Planning Dockless e-Bike Sharing Service in Chennai City:\n## Segmenting and Clustering Neighborhoods"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": " #### 1. Exploratory Analysis: Foursquare Seach for Venue Categories and Exploring Venues"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import pandas as pd\nimport numpy as np"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "##### Reading CSV file with list of 43 metro stations that has commuting data"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ChennaiNeighborhoods = pd.read_csv('ChennaiNeighborhoodsMP2v2.csv')\nChennaiNeighborhoods"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "import requests # library to handle requests\nfrom pandas.io.json import json_normalize # for tranforming json file into a pandas dataframe library"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "CLIENT_ID = 'OCGNXAFARHWAGWZ4BPFTF22JZFP0PRAGPBVSBGNUPQRIWB30' # Foursquare ID\nCLIENT_SECRET = 'L1NTEIW4IOTRCRWH23QRHWKLKHXR41VZ5S0IWJW0SQISLN33' # Foursquare Secret\nACCESS_TOKEN = 'GZNAS3DSI4HWH1LO3L2PXOXYKHKSTQ3JXKBGXJVXUCEC5HCL' # FourSquare Access Token\nVERSION = '20180604'\nLIMIT = 50\nprint('Credentials:')\nprint('CLIENT_ID: ' + CLIENT_ID)\nprint('CLIENT_SECRET:' + CLIENT_SECRET)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "radius = 1000\n\nChennaiNeighborhoodsFoodType = pd.DataFrame(columns = ['Restaurant','Hotel','Cafe'])\ndf_1 = pd.DataFrame()\ndf_2 = pd.DataFrame()\ndf_3 = pd.DataFrame()\n\nfor index in range(0, len(ChennaiNeighborhoods)):\n    latitude = ChennaiNeighborhoods.iloc[index]['Latitude']\n    longitude = ChennaiNeighborhoods.iloc[index]['Longitude']\n    \n    search_query_1 = 'Restaurant'\n    url_1 = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&oauth_token={}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude,ACCESS_TOKEN, VERSION, search_query_1, radius, LIMIT)\n    results_1 = requests.get(url_1).json()\n    venues_1 = results_1['response']['venues']\n    df_1 = json_normalize(venues_1)\n   \n    search_query_2 = 'Hotel'\n    url_2 = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&oauth_token={}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude,ACCESS_TOKEN, VERSION, search_query_2, radius, LIMIT)\n    results_2 = requests.get(url_2).json()\n    venues_2 = results_2['response']['venues']\n    df_2 = json_normalize(venues_2)\n\n    search_query_3 = 'Cafe'\n    url_3 = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&oauth_token={}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude,ACCESS_TOKEN, VERSION, search_query_3, radius, LIMIT)\n    results_3 = requests.get(url_3).json()\n    venues_3 = results_3['response']['venues']\n    df_3 = json_normalize(venues_3)\n    \n    ChennaiNeighborhoodsFoodType = ChennaiNeighborhoodsFoodType.append({'Restaurant':df_1.shape[0],'Hotel':df_2.shape[0],'Cafe':df_3.shape[0] }, ignore_index=True)\n    \nChennaiNeighborhoodsFoodType"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "radius = 1000\n\nChennaiNeighborhoodsShopType = pd.DataFrame(columns = ['Store','Shop','Market'])\ndf_4 = pd.DataFrame()\ndf_5 = pd.DataFrame()\ndf_6 = pd.DataFrame()\n\nfor index in range(0, len(ChennaiNeighborhoods)):\n    latitude = ChennaiNeighborhoods.iloc[index]['Latitude']\n    longitude = ChennaiNeighborhoods.iloc[index]['Longitude']\n    \n    search_query_4 = 'Store'\n    url_4 = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&oauth_token={}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude,ACCESS_TOKEN, VERSION, search_query_4, radius, LIMIT)\n    results_4 = requests.get(url_4).json()\n    venues_4 = results_4['response']['venues']\n    df_4 = json_normalize(venues_4)\n   \n    search_query_5 = 'Shop'\n    url_5 = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&oauth_token={}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude,ACCESS_TOKEN, VERSION, search_query_5, radius, LIMIT)\n    results_5 = requests.get(url_5).json()\n    venues_5 = results_5['response']['venues']\n    df_5 = json_normalize(venues_5)\n\n    search_query_6 = 'Market'\n    url_6 = 'https://api.foursquare.com/v2/venues/search?client_id={}&client_secret={}&ll={},{}&oauth_token={}&v={}&query={}&radius={}&limit={}'.format(CLIENT_ID, CLIENT_SECRET, latitude, longitude,ACCESS_TOKEN, VERSION, search_query_6, radius, LIMIT)\n    results_6 = requests.get(url_6).json()\n    venues_6 = results_6['response']['venues']\n    df_6 = json_normalize(venues_6)\n    \n    ChennaiNeighborhoodsShopType = ChennaiNeighborhoodsShopType.append({'Store':df_4.shape[0],'Shop':df_5.shape[0],'Market':df_6.shape[0] }, ignore_index=True)\n    \nChennaiNeighborhoodsShopType"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ChennaiNeighborhoods = ChennaiNeighborhoods.join(ChennaiNeighborhoodsFoodType)\nChennaiNeighborhoods = ChennaiNeighborhoods.join(ChennaiNeighborhoodsShopType)\nChennaiNeighborhoods"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ChennaiNeighborhoods['FoodVenues'] = ChennaiNeighborhoods[['Restaurant','Hotel','Cafe']].sum(axis=1).astype(int)\nChennaiNeighborhoods['ShopVenues'] = ChennaiNeighborhoods[['Store','Shop','Market']].sum(axis=1).astype(int)\nChennaiNeighborhoods"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ChennaiNeighborhoods['TotalVenues'] = ChennaiNeighborhoods[['FoodVenues','ShopVenues']].sum(axis=1).astype(int)\nChennaiNeighborhoods"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "%matplotlib inline\n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nmpl.style.use('ggplot') # optional: for ggplot-like style\n\n# check for latest version of Matplotlib\nprint('Matplotlib version: ', mpl.__version__) # >= 2.0.0"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ChennaiNeighborhoods.plot(kind='scatter', x='Boarding', y='Alighting', figsize=(12, 8), color='darkblue')\n\nplt.title('Correlation between Commuters Boarding and Alighting at each Metro Station')\nplt.xlabel('Commuters Boarding at each Metro Station')\nplt.ylabel('Commuters Alightng at each Metro Station')\n\nx = ChennaiNeighborhoods['Boarding']      # year on x-axis\ny = ChennaiNeighborhoods['Alighting']     # total on y-axis\nfit = np.polyfit(x, y, deg=1)\n\nfit\n\nplt.plot(x, fit[0] * x + fit[1], color='red') # recall that x is the Years\n\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "##### Estimated count of commuters boarding at each station is correlated with the count of commuters alighting at the respective station.\n##### This two-way proportional-flow of estimated commuters increases the likelihood of e-bikes getting utilized continuously."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ChennaiNeighborhoods.plot(kind='scatter', x='TotalVenues', y='TotalCommuters', figsize=(12, 8), color='darkblue')\n\nplt.title('Corelation between Total-Commuters and Total-Venues around each Metro Station')\nplt.xlabel('Total Venues - Shopping Spaces and Dining Spaces')\nplt.ylabel('Total Commuters - Boarding and Alighting at each Metro Station')\n\nx = ChennaiNeighborhoods['TotalVenues']      # year on x-axis\ny = ChennaiNeighborhoods['TotalCommuters']     # total on y-axis\nfit = np.polyfit(x, y, deg=1)\n\nfit\n\nplt.plot(x, fit[0] * x + fit[1], color='red') # recall that x is the Years\n\nplt.show()"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "##### Correlation between total-commuters and total-venues (dining + shopping spaces) can be observed.\n##### This linear relationship (increase in commuters for an increase in venues) builds the case for profitable operations of e-bike service if the dock-less e-bike zones can be located around those stations where both the categories of venues exist among its common venues."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### 2. Segmentation and Clustering Neighbourhoods/Stations"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "ChennaiNeighborhoods = pd.read_csv('ChennaiNeighborhoodsMP1and2v2.csv')\nChennaiNeighborhoods"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\n\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\n!pip install folium==0.5.0\nimport folium # map rendering library\n\nprint('Libraries imported.')"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "!pip install geopy\nfrom geopy.geocoders import Nominatim # convert an address into latitude and longitude values\nLIMIT = 100 # A default Foursquare API limit value\naddress = 'Chennai, India'\n\ngeolocator = Nominatim(user_agent=\"Chennai_explorer\")\nlocation = geolocator.geocode(address)\nlatitude = location.latitude\nlongitude = location.longitude\nprint('The geograpical coordinates of Chennai City are {}, {}.'.format(latitude, longitude))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map of Chennai city using latitude and longitude values\nmap_chennai = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# add markers to map\nfor lat, lng, neighborhood in zip(ChennaiNeighborhoods['Latitude'], ChennaiNeighborhoods['Longitude'], ChennaiNeighborhoods['Neighborhood']):\n    label = '{}'.format(neighborhood)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7,\n        parse_html=False).add_to(map_chennai)  \n    \nmap_chennai"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def getNearbyVenues(names, latitudes, longitudes, radius=1000):\n    \n    venues_list=[]\n    for name, lat, lng in zip(names, latitudes, longitudes):\n        print(name)\n            \n        # create the API request URL\n        url = 'https://api.foursquare.com/v2/venues/explore?&client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}'.format(\n            CLIENT_ID, \n            CLIENT_SECRET, \n            VERSION, \n            lat, \n            lng, \n            radius, \n            LIMIT)\n            \n        # make the GET request\n        results = requests.get(url).json()[\"response\"]['groups'][0]['items']\n        \n        # return only relevant information for each nearby venue\n        venues_list.append([(\n            name, \n            lat, \n            lng, \n            v['venue']['name'], \n            v['venue']['location']['lat'], \n            v['venue']['location']['lng'],  \n            v['venue']['categories'][0]['name']) for v in results])\n\n    nearby_venues = pd.DataFrame([item for venue_list in venues_list for item in venue_list])\n    nearby_venues.columns = ['Neighborhood', \n                  'Neighborhood Latitude', \n                  'Neighborhood Longitude', \n                  'Venue', \n                  'Venue Latitude', \n                  'Venue Longitude', \n                  'Venue Category']\n    \n    return(nearby_venues)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "chennai_venues = getNearbyVenues(names=ChennaiNeighborhoods['Neighborhood'],\n                                   latitudes=ChennaiNeighborhoods['Latitude'],\n                                   longitudes=ChennaiNeighborhoods['Longitude']\n                                  )"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print(chennai_venues.shape)\nchennai_venues.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "chennai_venues.groupby('Neighborhood').count()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('There are {} uniques categories.'.format(len(chennai_venues['Venue Category'].unique())))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# one hot encoding\nchennai_onehot = pd.get_dummies(chennai_venues[['Venue Category']], prefix=\"\", prefix_sep=\"\")\n\n# drop neighborhood column, as it is found to be one of the venue categories\n#chennai_onehot = chennai_onehot.drop(columns='Neighborhood')\n\n# copy the actual neighborhood column from venues dataframe to the first column of onehot encoded dataframe\nchennai_onehot.insert(loc=0, column='Neighborhood', value=chennai_venues['Neighborhood'])\nchennai_onehot"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "chennai_grouped = chennai_onehot.groupby('Neighborhood').mean().reset_index()\nchennai_grouped"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "def return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "num_top_venues = 10\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['Neighborhood']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\nneighborhoods_venues_sorted = pd.DataFrame(columns=columns)\nneighborhoods_venues_sorted['Neighborhood'] = chennai_grouped['Neighborhood']\n\nfor ind in np.arange(chennai_grouped.shape[0]):\n    neighborhoods_venues_sorted.iloc[ind, 1:] = return_most_common_venues(chennai_grouped.iloc[ind, :], num_top_venues)\n\nneighborhoods_venues_sorted.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# set number of clusters\nkclusters = 2\n\nchennai_grouped_clustering = chennai_grouped.drop('Neighborhood', 1)\n\n# run k-means clustering\nkmeans = KMeans(n_clusters=kclusters, random_state=0).fit(chennai_grouped_clustering)\n\n# check cluster labels generated for each row in the dataframe\nkmeans.labels_"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# add clustering labels\n\nneighborhoods_venues_sorted.insert(0, 'ClusterLabels', kmeans.labels_)\n\nchennai_merged = ChennaiNeighborhoods\n\n# merge toronto_grouped with toronto_data to add latitude/longitude for each neighborhood\nchennai_merged = chennai_merged.join(neighborhoods_venues_sorted.set_index('Neighborhood'), on='Neighborhood')\n\nchennai_merged = chennai_merged.astype({\"ClusterLabels\": int})\nchennai_merged"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# create map\nmap_clusters = folium.Map(location=[latitude, longitude], zoom_start=12)\n\n# set color scheme for the clusters\nx = np.arange(kclusters)\nys = [i + x + (i*x)**2 for i in range(kclusters)]\ncolors_array = cm.rainbow(np.linspace(0, 1, len(ys)))\nrainbow = [colors.rgb2hex(i) for i in colors_array]\n\n# add markers to the map\nmarkers_colors = []\nfor lat, lon, poi, cluster in zip(chennai_merged['Latitude'], chennai_merged['Longitude'], chennai_merged['Neighborhood'], chennai_merged['ClusterLabels']):\n    label = folium.Popup(str(poi) + ' Cluster ' + str(cluster), parse_html=True)\n    folium.CircleMarker(\n        [lat, lon],\n        radius=5,\n        popup=label,\n        color=rainbow[cluster-1],\n        fill=True,\n        fill_color=rainbow[cluster-1],\n        fill_opacity=0.7).add_to(map_clusters)\n       \nmap_clusters"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "chennai_merged.loc[chennai_merged['ClusterLabels'] == 0, chennai_merged.columns[[1] + list(range(5, chennai_merged.shape[1]))]]"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "chennai_merged.loc[chennai_merged['ClusterLabels'] == 1, chennai_merged.columns[[1] + list(range(5, chennai_merged.shape[1]))]]"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "#### 3. Observations/Recommendations:\n##### The second cluster had equal-distribution of venue-categories (food-venues and shop/other-venues) among its 10-most common venue categories, at an aggregate-level.\n##### It can be recommended that this cluster with 21 neighbourhoods/stations are the candidates among 59 stations considered for analysis (or 132 metro stations in all), for rolling out e-bike shared mobility service, that can potentially turn profitable to the prospective service provider.\n##### Upon these stations/neighbourhood locations turning profitable, service provider(s) can choose to scale-out the shared mobility services to other locations in a phased manner."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python",
            "language": "python",
            "name": "conda-env-python-py"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}